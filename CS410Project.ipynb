{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS410Project2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mKSgCPUFM3k"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37N12UgKFTzb"
      },
      "source": [
        "import pandas as pd\r\n",
        "import torch\r\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\r\n",
        "import json\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umXXJJCl73ic"
      },
      "source": [
        "# The Huggingface model trainer uses Dataset objects extended from the PyTorch Dataset type\r\n",
        "# This custom subclass returns each datum in the format the trainer will be looking for\r\n",
        "class CustomDataset(torch.utils.data.Dataset):\r\n",
        "    def __init__(self, encodings, labels):\r\n",
        "        self.encodings = encodings\r\n",
        "        self.labels = labels\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\r\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\r\n",
        "        return item\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1aM_PaRFiEU"
      },
      "source": [
        "# Read in data\n",
        "with open('train.jsonl') as f:\n",
        "  train_data = [json.loads(jline) for jline in f.readlines()]\n",
        "\n",
        "with open('test.jsonl', 'r') as f:\n",
        "  test_data = [json.loads(jline) for jline in f.readlines()]\n",
        "\n",
        "# initialize the BERT pretrained model (with associated tokenizer)\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6pbdSpeOYEc"
      },
      "source": [
        "# Method to remove whitespace and a few tokens that are meaningless due to sanitazation\r\n",
        "def process_text(text):\r\n",
        "  return text.replace('@USER', '').replace('<URL>', '').strip()\r\n",
        "\r\n",
        "\r\n",
        "# Also replace the label text with 0/1 and append the most immediate context tweet to the response\r\n",
        "# This ended up helping accuracy significantly\r\n",
        "train_labels = [ 1 if x['label'] == 'SARCASM' else 0 for x in train_data]\r\n",
        "train_text = [process_text(x['context'][-1]) + ' ' + process_text(x['response']) for x in train_data]\r\n",
        "test_text = [process_text(x['context'][-1]) + ' ' + process_text(x['response']) for x in test_data]\r\n",
        "\r\n",
        "# Create training, validation sets, along with the final test set to make predictions against\r\n",
        "train_text, val_text, train_labels, val_labels = train_test_split(train_text, train_labels, test_size=0.05)\r\n",
        "\r\n",
        "# The BERT model takes in encoded values standing in for the text\r\n",
        "train_encoding = tokenizer(train_text, return_tensors='pt', padding=True, truncation=True)\r\n",
        "val_encoding = tokenizer(val_text, return_tensors='pt', padding=True, truncation=True)\r\n",
        "test_encoding = tokenizer(test_text, return_tensors='pt', padding=True, truncation=True)\r\n",
        "\r\n",
        "train_ds = CustomDataset(train_encoding, train_labels)\r\n",
        "val_ds = CustomDataset(val_encoding, val_labels)\r\n",
        "test_ds = CustomDataset(test_encoding, [0 for i in range(len(test_data))])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5UDBLR0GtPL"
      },
      "source": [
        "# Train the BERT model with our situational data. 5 epochs ended up enough to beat the baseline\r\n",
        "training_args = TrainingArguments(\r\n",
        "    output_dir='./results',\r\n",
        "    num_train_epochs=5,\r\n",
        "    per_device_train_batch_size=16,\r\n",
        "    per_device_eval_batch_size=64,\r\n",
        "    warmup_steps=500,\r\n",
        "    weight_decay=0.01,\r\n",
        "    logging_dir='./logs',\r\n",
        "    logging_steps=10,\r\n",
        ")\r\n",
        "\r\n",
        "trainer = Trainer(\r\n",
        "    model=model,\r\n",
        "    args=training_args,\r\n",
        "    train_dataset=train_ds,\r\n",
        "    eval_dataset=val_ds\r\n",
        ")\r\n",
        "\r\n",
        "trainer.train()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbUnPg_2XBks"
      },
      "source": [
        "# Predictions are returned as logit ranges, so they need to be processed with softmax to get probabilites\r\n",
        "pred = trainer.predict(test_ds)\r\n",
        "pred_tensor = torch.tensor(pred.predictions)\r\n",
        "probs = torch.nn.functional.softmax(pred_tensor, dim=-1).tolist()\r\n",
        "\r\n",
        "# Write predictions to desired format for competition\r\n",
        "with open('answer.txt', 'w') as f:\r\n",
        "  for i in range(len(probs)):\r\n",
        "    result = 'SARCASM' if probs[i][0] < probs[i][1] else 'NOT_SARCASM'\r\n",
        "    f.write('twitter_' + str(i+1) + ',' + result + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}